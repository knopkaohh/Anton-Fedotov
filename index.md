# Машинное обучение
## Введение

Развитие современной технологии показывает недостаток знаний человеком и необходимость создания искусственного интеллекта, который бесспорно бы явился помощником человека, в решении ряда проблем, в том числе глобального характера. 

В наши дни информация вышла на приоритетное место среди критериев прогресса, как и средства ее получения, обработке и использования — компьютер и компьютерные технологии, с помощью которых это осуществляется, активно развиваются. 

Каждый из нас когда-нибудь пользовался голосовым помощником Google или Siri, но никто не задумывался, почему, если мы, например, говорим Siri «Привет», она отвечает нам именно «Привет», а не «Пока» например. Нам стало интересно, как ничего не понимающий робот может отвечать человеку и даже вести с ним диалог. Именно поэтому мы и решили больше узнать об искусственном интеллекте.

## История машинного обучения
В 1959 году Артур Самуэль, исследователь искусственного интеллекта, ввел термин «машинное обучение». Он изобрел первую самообучающуюся компьютерную программу по игре в шашки. Самуэль определил машинное обучение как процесс, в результате которого компьютеры способны показать такое поведение, которое в них не было запрограммировано изначально.

Ниже рассмотрим другие важные даты в истории машинного обучения:

1946: Появился компьютер ЭНИАК — сверхсекретный проект армии США.

1950: Алан Тьюринг создает “Тьюринг тест” для оценки интеллекта компьютера.

1958: Фрэнк Розенблатт придумал Персептрон — первую искусственную нейронную сеть и создал первый нейрокомпьютер «Марк-1».

1959: Марвин Минский создал первую машину SNARC со случайно связанной нейросетью.

1967: Написан метрический алгоритм по классификации данных. Алгоритм позволил компьютерам применять простые шаблоны распознавания.

1985: Терри Сейновски создает NetTalk — искусственную нейронную сеть.

1997: Компьютер Deep Blue обыграл чемпиона мира, Гарри Каспарова, в шахматы.

2006: Джеффри Хинтон, ученый в области искусственных нейросетей, ввел термин «Глубинное обучение» (Deep learning).

2011: Эндрю Энг и Джефф Дин основали Google Brain.

2012: В Google X Lab разработали алгоритм, позволяющий идентифицировать видеоролики, в которых показываются коты :)

2012: Google запускает облачный сервис Google Prediction API для машинного обучения. Он помогает анализировать неструктурированные данные.

2014: В Facebook изобрели DeepFace для распознавания лиц. Точность алгоритма 97%.

2015: Amazon запустила собственную платформу машинного обучения — Amazon Machine Learning.

2015: Microsoft создает платформу Distributed Learning Machine Toolkit, предназначенную для децентрализованного машинного обучения.

2020: Технологии искусственного интеллекта применяются практически в каждом программном продукте.

## Суть технологии машинного обучения

Машинное обучение (Machine Learning) это тренировка математической модели на исторических данных для того, чтобы прогнозировать какое-то событие или явление на новых данных. То есть попытка заставить алгоритмы программ совершать действия на основе предыдущего опыта, а не только на основе имеющихся данных. 

Для обучения нужны исторические данные (обучающая выборка) и значение целевой переменной (то, что прогнозируем), которое соответствует заданным историческим данным. Модель наблюдает и находит зависимости между данными и целевой переменной. Эти зависимости используются моделью для нового набора данных, чтобы прогнозировать целевую переменную, которая неизвестна. 

Машинное обучение включает в себя целый набор методов и алгоритмов, которые могут предсказать какой-то результат по входным данным. Например, у вас есть какая-то информация по тому, сколько стоили ценные бумаги в каждый момент из какого-то длинного промежутка времени, алгоритмы машинного обучения могут предсказать, сколько эти бумаги будут стоить в будущем.

# Методы машинного обучения
## С учителем
Обучение с учителем (supervised learning) — наиболее распространённый случай. Каждый прецедент представляет собой пару «объект, ответ». Требуется найти функциональную зависимость ответов от описаний объектов и построить алгоритм, принимающий на входе описание объекта и выдающий на выходе ответ. Функционал качества обычно определяется как средняя ошибка ответов, выданных алгоритмом, по всем объектам выборки. 

Так, например, программы учат распознавать объекты на фотографиях – программа просматривает миллионы изображений с описанием того, что на них изображено (дерево или облако). Она находит общие черты и уже сама учится давать описания изображениям. Учитель показывает изображение без описания, а программа спрашивает «это дерево?». Если человек отвечает утвердительно, программа понимает, что сделала правильные выводы. Хороший пример такой системы – облачный сервис для встраивания в приложения машинного зрения Vision на платформе Mail.Ru Cloud Solutions. 

Систему распознавания объектов можно использовать для обеспечения работы беспилотных автомобилей. Для этого собираются данные с датчиков беспилотника и передаются пользователям, которые, к примеру, отмечают на снимках автомобили

Существует несколько задач, которые решаются с помощью метода «с учителем»:

•	Задача классификации (classification) отличается тем, что множество допустимых ответов конечно. Их называют метками классов (class label). Класс — это множество всех объектов с данным значением метки

•	Задача регрессии (regression) отличается тем, что допустимым ответом является действительное число или числовой вектор. 

•	Задача ранжирования (learning to rank) отличается тем, что ответы надо получить сразу на множестве объектов, после чего отсортировать их по значениям ответов. Может сводиться к задачам классификации или регрессии. Часто применяется в информационном поиске и анализе текстов.

•	Задача прогнозирования (forecasting) отличается тем, что объектами являются отрезки временных рядов, обрывающиеся в тот момент, когда требуется сделать прогноз на будущее. Для решения задач прогнозирования часто удаётся приспособить методы регрессии или классификации, причём во втором случае речь идёт скорее о задачах принятия решений.

## Без учителя

Обучение без учителя (Unsupervised learning) — один из разделов машинного обучения. Изучает широкий класс задач обработки данных, в которых известны только описания множества объектов (обучающей выборки), и требуется обнаружить внутренние взаимосвязи, зависимости, закономерности, существующие между объектами. 

Обучение без учителя часто противопоставляется обучению с учителем, когда для каждого обучающего объекта задаётся «правильный ответ», и требуется найти зависимость между объектами и ответами. 

Такой подход изучается для выполнения тех задач, где присутствует неочевидное решение. Например, в том же маркетинге. ИИ не понимает, что предлагать похожий товар человеку, который в нем не нуждается, нелогично, если это приносит деньги. Также нейросети могут обучаться не самостоятельно, а в паре. Так работает генеративно-состязательная сеть (GAN). Она состоит из сетей G и D – первая на основе реальных изображений генерирует образцы, а вторая пытается отличить подлинные образцы от неправильных. 

Технология используется для того, чтобы создавать фотографии, неотличимые от реальных, а также восстанавливать поврежденные или нечеткие изображения. Одна из компаний, которая использует GAN, – Facebook.

Существует несколько задач, которые решаются с помощью метода «без учителя»:

•	Задача кластеризации (clustering) заключается в том, чтобы сгруппировать объекты в кластеры, используя данные о попарном сходстве объектов. Функционалы качества могут определяться по-разному, например, как отношение средних межкластерных и внутрикластерных расстояний. 

•	Задача поиска ассоциативных правил (association rules learning). Исходные данные представляются в виде признаковых описаний. Требуется найти такие наборы признаков, и такие значения этих признаков, которые особенно часто (неслучайно часто) встречаются в признаковых описаниях объектов.

•	Задача фильтрации выбросов (outliers detection) — обнаружение в обучающей выборке небольшого числа нетипичных объектов. В некоторых приложениях их поиск является самоцелью (например, обнаружение мошенничества). В других приложениях эти объекты являются следствием ошибок в данных или неточности модели, то есть шумом, мешающим настраивать модель, и должны быть удалены из выборки, см. также робастные методы и одноклассовая классификация.

•	Задача построения доверительной области (quantile estimation) — области минимального объёма с достаточно гладкой границей, содержащей заданную долю выборки.

•	Задача сокращения размерности (dimensionality reduction) заключается в том, чтобы по исходным признакам с помощью некоторых функций преобразования перейти к наименьшему числу новых признаков, не потеряв при этом никакой существенной информации об объектах выборки. В классе линейных преобразований наиболее известным примером является метод главных компонент. 

•	Задача заполнения пропущенных значений (missing values) — замена недостающих значений в матрице объекты–признаки их прогнозными значениями.

## Глубокое обучение

Глубокое обучение может быть как с учителем, так и без, но оно подразумевает под собой анализ Big Data – настолько большой информации, что одного компьютера будет недостаточно. Поэтому Deep Learning использует для работы нейронные сети. Нейронные сети позволяют разделить одну большую задачу на несколько маленьких и делегировать их другим устройствам. Например, один процессор собирает информацию и передает ее двум другим. Те, в свою очередь, анализируют ее и передают еще четырем, которые выполняют еще какие-то задачи и передают следующим процессорам. Это можно рассмотреть на примере систем распознавания объектов: 

1. получение изображения; 
2. выявление всех точек; 
3. нахождение линий, построенных из точек;
4. построение простых фигур с помощью линий; 
5. составление сложных фигур из простых и так далее.

# Примеры реального использования машинного обучения
## Google - нейтронные сети

У Google впечатляющие технологические амбиции. Сложно представить себе сферу научных исследований, в которую бы не внесла вклад эта корпорация (или ее головная компания Alphabet). Например, за последние годы Google занимались разработкой технологий, замедляющих старение, медицинских устройств и нейронных сетей. Самое значимое достижение компании – создание в DeepMind машин, которые могут мечтать и создавать необычные изображения. 
 
Google стремится изучить все аспекты машинного обучения, что помогает компании совершенствовать классические алгоритмы, а также эффективнее обрабатывать и переводить естественную речь, улучшать ранжирование и предсказательные системы.

## Twitter – новостная лента

Одно из самых значимых изменений в Twitter за последнее время – переход к новостной ленте на базе алгоритмов. Теперь пользователи соцсети могут сортировать отображаемый контент по популярности или по времени публикации. В основе этих изменений лежит применение машинного обучения. Искусственный интеллект анализирует каждый твит в реальном времени и оценивает его по нескольким показателям. Алгоритм Twitte в первую очередь показывает те записи, которые с большей вероятностью понравятся пользователю. При этом выбор основывается на его личных предпочтениях.

## Facebook – армия чатботов

Facebook Messenger – один из самых интересных продуктов крупнейшей социальной платформы в мире. Все потому, что мессенджер стал своеобразной лабораторией чатботов. При общении с некоторыми из них сложно понять, что ты разговариваешь не с человеком. Любой разработчик может и запустить его на базе Facebook Messenger. Благодаря этому даже небольшие компании имеют возможность предлагать клиентам отличный сервис. Конечно, это не единственная сфера применения машинного обучения в Facebook. AI приложения используются для фильтрации спама и контента низкого качества, также компания разрабатывает алгоритмы компьютерного зрения, которые позволяют компьютерам “читать” изображения.

## Baidu — будущее голосового поиска

Google не единственный поисковой гигант, который осваивает машинное обучение. Китайский поисковик Baidu тоже активно инвестирует в развитие AI. Одна из самых интересных разработок компании – Deep Voice, нейронная сеть, способная генерировать синтетические человеческие голоса, которые практически невозможно отличить от настоящих. Система может имитировать особенности интонации, произношения, ударения и высоты тона. Последнее изобретение Baidu Deep Voice 2 значительно повлияет на эффективность обработки естественного языка, голосового поиска и систем распознавания речи. Применять новую технологию можно будет в других сферах, например, устных переводах и системах биометрической безопасности.

## IBM – здравоохранение нового поколения

Крупнейшая технологическая корпорация IBM отказывается от устаревшей бизнес-модели и активно осваивает новые направления. Самый известный сегодня продукт бренда – искусственный интеллект Watson. За последние несколько лет Watson использовался в госпиталях и медицинских центрах, где диагностировал определенные виды рака намного эффективнее, чем онкологи. У Watson также есть огромный потенциал в сфере ритейла, где он может выполнять роль консультанта. IBM предлагает свой продукт на основе лицензии, что делает его уникальным в своем роде и более доступным.

# Заключение

В результате проведённого исследования поставленная цель достигнута – изучен принцип работы машинного обучение и его методы, а так же построена собственная модель машинного обучения. Поставленные задачи решены:

•	Изучена научная литература, публикации, статьи по данной теме; 

•	Проведено исследование реальной модели машинного обучения; 

•	Изучено устройство и принцип работы машинного обучения 

Таким образом, благодаря машинному обучения и большим вычислительным мощностях вычислительной техники, человек способен анализировать большие базы данных. Кроме того, эта область имеет огромный потенция для развития в будущем. Итак, с помощью машинного обучения человек может с большой точностью прогнозировать события, создавать новые зависимости одних данных от других.
